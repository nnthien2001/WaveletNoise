{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pywt\n",
    "from scipy.signal import wiener\n",
    "import skimage as skimg \n",
    "\n",
    "from sklearn.preprocessing import (MinMaxScaler, StandardScaler)\n",
    "# from sklearn.model_selection import (train_test_split,)\n",
    "from sklearn.model_selection import (train_test_split, StratifiedKFold,)\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import (SVC)\n",
    "\n",
    "from sklearn.base import (BaseEstimator, TransformerMixin)\n",
    "from sklearn.pipeline import (make_pipeline, make_union,)\n",
    "from sklearn.metrics import (classification_report, accuracy_score)\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLASS():\n",
    "    FAKE = 0\n",
    "    REAL = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_PREFIX = '/home/thienn17/Documents/ICL/'\n",
    "os.path.exists(PATH_PREFIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadImage():\n",
    "    def __init__(self, path_prefix, colorcvt=None):\n",
    "        assert os.path.exists(path_prefix), \"LoadImage, Path does not exist\"\n",
    "        self.path_prefix = path_prefix\n",
    "        self.colorcvt = colorcvt\n",
    "\n",
    "        self.cls_folders = [f for f in os.listdir(path_prefix) if f == 'dummy']\n",
    "        self.cls_id = 0\n",
    "        self.path_walk = os.walk(os.path.join(path_prefix, self.cls_folders[0]))\n",
    "        \n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "    \n",
    "    def reset(self):\n",
    "        self.images = []\n",
    "    \n",
    "    def next_batch(self):\n",
    "        try:\n",
    "            while(True):\n",
    "                abspath, _, files = next(self.path_walk)\n",
    "                if len(files) > 0: break\n",
    "            self.reset()\n",
    "            print(abspath)\n",
    "            for file in tqdm(files):\n",
    "                img = cv2.imread(os.path.join(abspath, file))\n",
    "                \n",
    "                # up_left = (np.array(img.shape[:2], dtype=np.int16) // 2) - 500\n",
    "                # # print(up_left)\n",
    "                # img = img[up_left[0]:up_left[0]+1000, up_left[0]:up_left[0]+1000]\n",
    "                # # print(img.shape)\n",
    "                # # return\n",
    "                \n",
    "                if img is not None:\n",
    "                    if self.colorcvt is not None:\n",
    "                        img = cv2.cvtColor(img, self.colorcvt)\n",
    "                    self.images.append(img)\n",
    "                    self.labels.append(CLASS.REAL if self.cls_folders[self.cls_id][0] == 'S' else CLASS.FAKE)\n",
    "            return self.images, self.labels\n",
    "        except StopIteration:\n",
    "            if self.cls_id < len(self.cls_folders)-1:\n",
    "                self.cls_id += 1\n",
    "                self.path_walk = os.walk(os.path.join(self.path_prefix, self.cls_folders[self.cls_id]))\n",
    "                return self.next_batch()\n",
    "\n",
    "        return None\n",
    "\n",
    "    def next_batch_new(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveletTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, wtname = 'haar', level = 3):\n",
    "        '''\n",
    "        waveletname = ['haar', 'db3', 'db5', 'sym2', 'bior5.5', etc.]\n",
    "        level: total number of decomposite level\n",
    "        '''\n",
    "        self.wtname = wtname\n",
    "        self.level = level\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        features = []\n",
    "        for imgBGR in tqdm(X):\n",
    "            img_features = []\n",
    "            for img in np.moveaxis(imgBGR, -1, 0):\n",
    "                wt = pywt.wavedec2(data=img, wavelet=self.wtname, level=self.level)\n",
    "                appr = wt[0]\n",
    "                details = wt[1:]\n",
    "                wt = [appr]\n",
    "                for levels in details:\n",
    "                    for detail in levels:\n",
    "                        wt.append(detail)\n",
    "                for _wt in wt:\n",
    "                    img_features.append(np.mean(_wt))\n",
    "                    img_features.append(np.var(_wt))\n",
    "                    # img_features.append(np.mean((_wt - np.mean(_wt))**3))\n",
    "            features.append(img_features)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LBPTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, num_points = 8, radius = 1, gray=False, noise=False):\n",
    "        self.num_points = num_points\n",
    "        self.radius = radius\n",
    "        self.gray = gray\n",
    "        self.noise = noise\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        features = []\n",
    "        for img in tqdm(X):\n",
    "            if self.gray:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                if self.noise:\n",
    "                    img = img - wiener(img, 5)\n",
    "                features.append(self.get_lbp_features((img,)))\n",
    "            else:\n",
    "                # print(img.shape)\n",
    "                features.append(self.get_lbp_features(np.moveaxis(img, -1, 0)))\n",
    "        return features\n",
    "\n",
    "    def local_binary_pattern(self, img, normalized=True):\n",
    "        lbp = skimg.feature.local_binary_pattern(\n",
    "            img, self.num_points, self.radius, method=\"nri_uniform\").ravel()\n",
    "        (hist, bins) = np.histogram(lbp.ravel(), bins=59)\n",
    "        # bins, hist = np.unique(lbp, return_counts=True)\n",
    "        \n",
    "        if normalized is False:\n",
    "            return hist\n",
    "        hist = hist / len(lbp)\n",
    "        return hist\n",
    "\n",
    "    def get_lbp_features(self, img_channels):\n",
    "        lbp_features = np.zeros(59)\n",
    "        for img in img_channels:\n",
    "            lbp_features += self.local_binary_pattern(img)\n",
    "        return lbp_features / len(img_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract & Dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wavelet\n",
    "LEVEL = 3\n",
    "extractor = WaveletTransformer(wtname='db5',level=LEVEL)\n",
    "A = np.empty((1, 3*2*(3*LEVEL+1)))  # channels * #feature * (#high_img * levels + #low-img)\n",
    "# A = np.empty((1,3*2*3*LEVEL))\n",
    "\n",
    "# # LBP\n",
    "# extractor = LBPTransformer()\n",
    "# A = np.empty((1, 59))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1\n",
      "/home/thienn17/Documents/ICL/dummy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  8.60it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "b = None\n",
    "loader = LoadImage(PATH_PREFIX, colorcvt=None)\n",
    "batch = 1\n",
    "while(True):\n",
    "    print(\"Batch {}\".format(batch))\n",
    "    batch += 1\n",
    "\n",
    "    res = loader.next_batch()\n",
    "    if res is None:\n",
    "        break\n",
    "    images, b = res\n",
    "    A = np.concatenate((A, extractor.transform(images)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2345, 60)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = A[1:]\n",
    "b = np.array(b)\n",
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_DUMP = \"./object dump/no union\"\n",
    "os.path.exists(PATH_DUMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE = \"a\"\n",
    "np.save(os.path.join(PATH_DUMP, FILE+\".npy\"), A)\n",
    "np.save(os.path.join(PATH_DUMP, FILE+\"_label.npy\"), b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_DUMP = \"./object dump/no union\"\n",
    "os.path.exists(PATH_DUMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2345, 60)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILE = \"wt_YCC_3lv_db5\"\n",
    "A = np.load(os.path.join(PATH_DUMP, FILE+\".npy\"))\n",
    "b = np.load(os.path.join(PATH_DUMP, FILE+\"_label.npy\"))\n",
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2345, 119)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILE = \"wt_BGR_3lv_db5\"\n",
    "FILE2 = \"lbp_HSV\"\n",
    "assert np.all(np.load(os.path.join(PATH_DUMP, FILE+\"_label.npy\")) == np.load(os.path.join(PATH_DUMP, FILE2+\"_label.npy\"))), \"Different order\"\n",
    "\n",
    "A = np.concatenate((np.load(os.path.join(PATH_DUMP, FILE+\".npy\")),\n",
    "                    np.load(os.path.join(PATH_DUMP, FILE2+\".npy\"))),\n",
    "                   axis=1)\n",
    "b = np.load(os.path.join(PATH_DUMP, FILE+\"_label.npy\"))\n",
    "A.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_train, A_test, b_train, b_test = train_test_split(A, b,\n",
    "                                                    train_size=0.8,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), SVC())\n",
    "pipe = pipe.fit(A_train, b_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.00      0.01       246\n",
      "           1       0.50      0.99      0.66       246\n",
      "\n",
      "    accuracy                           0.50       492\n",
      "   macro avg       0.37      0.50      0.34       492\n",
      "weighted avg       0.37      0.50      0.34       492\n",
      "\n"
     ]
    }
   ],
   "source": [
    "b_pred = pipe.predict(A_test)\n",
    "print(classification_report(b_test, b_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold(_estimator):\n",
    "    # print(_estimator)\n",
    "    \n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    score = 0\n",
    "    for k, (i_train, i_test) in enumerate(kf.split(A, b)):\n",
    "        model = _estimator.fit(A[i_train,], b[i_train])\n",
    "\n",
    "        y_pred = model.predict(A[i_test,])\n",
    "        acc = accuracy_score(y_true=b[i_test], y_pred=y_pred)\n",
    "        score += acc\n",
    "\n",
    "        print(\"[Fold {}] Acc: {:.3f}\".format(k+1, acc))\n",
    "        # print(classification_report(y_true=b[i_test], y_pred=y_pred))\n",
    "\n",
    "    print(\"Mean acc: {:.3f}\\n\".format(score/kf.get_n_splits()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1] Acc: 1.000\n",
      "[Fold 2] Acc: 1.000\n",
      "[Fold 3] Acc: 1.000\n",
      "[Fold 4] Acc: 0.990\n",
      "[Fold 5] Acc: 1.000\n",
      "Mean acc: 0.998\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(StandardScaler(), SVC())\n",
    "kfold(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "[Fold 1] Acc: 0.987\n",
    "[Fold 2] Acc: 0.972\n",
    "[Fold 3] Acc: 0.977\n",
    "[Fold 4] Acc: 0.985\n",
    "[Fold 5] Acc: 0.983\n",
    "Mean acc: 0.981\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cable\n",
    "\n",
    "Ignore this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_PREFIX = '/home/thienn17/Documents/Cable/'\n",
    "os.path.exists(PATH_PREFIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadImageCable():\n",
    "    def __init__(self, path_prefix, colorcvt=None):\n",
    "        assert os.path.exists(path_prefix), \"LoadImage, Path does not exist\"\n",
    "        self.path_prefix = path_prefix\n",
    "        self.colorcvt = colorcvt\n",
    "\n",
    "        self.cls_folders = [f for f in os.listdir(path_prefix) if f != 'dummy']\n",
    "        self.cls_id = 0\n",
    "        self.path_walk = os.walk(os.path.join(path_prefix, self.cls_folders[0]))\n",
    "        \n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "    \n",
    "    def reset(self):\n",
    "        self.images = []\n",
    "    \n",
    "    def next_batch(self):\n",
    "        try:\n",
    "            while(True):\n",
    "                abspath, _, files = next(self.path_walk)\n",
    "                if len(files) > 0: break\n",
    "            self.reset()\n",
    "            print(abspath)\n",
    "            for file in tqdm(files):\n",
    "                img = cv2.imread(os.path.join(abspath, file))\n",
    "                \n",
    "                if img is not None:\n",
    "                    if self.colorcvt is not None:\n",
    "                        img = cv2.cvtColor(img, self.colorcvt)\n",
    "                    self.images.append(img)\n",
    "                    self.labels.append(CLASS.REAL if self.cls_folders[self.cls_id] == 'real' else CLASS.FAKE)\n",
    "            return self.images, self.labels\n",
    "        except StopIteration:\n",
    "            if self.cls_id < len(self.cls_folders)-1:\n",
    "                self.cls_id += 1\n",
    "                self.path_walk = os.walk(os.path.join(self.path_prefix, self.cls_folders[self.cls_id]))\n",
    "                return self.next_batch()\n",
    "\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wavelet\n",
    "LEVEL = 3\n",
    "extractor = WaveletTransformer(wtname='db5',level=LEVEL)\n",
    "A = np.empty((1, 3*2*(3*LEVEL+1)))  # channels * #feature * (#high_img * levels + #low-img)\n",
    "# A = np.empty((1,3*2*3*LEVEL))\n",
    "\n",
    "# # LBP\n",
    "# extractor = LBPTransformer()\n",
    "# A = np.empty((1, 59))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1\n",
      "/home/thienn17/Documents/Cable/recap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [01:12<00:00,  3.39it/s]\n",
      "100%|██████████| 246/246 [05:42<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2\n",
      "/home/thienn17/Documents/Cable/real\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:01<00:00, 208.68it/s]\n",
      "100%|██████████| 246/246 [00:04<00:00, 51.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "b = None\n",
    "loader = LoadImageCable(PATH_PREFIX, colorcvt=cv2.COLOR_BGR2YCrCb)\n",
    "batch = 1\n",
    "while(True):\n",
    "    print(\"Batch {}\".format(batch))\n",
    "    batch += 1\n",
    "\n",
    "    res = loader.next_batch()\n",
    "    if res is None:\n",
    "        break\n",
    "    images, b = res\n",
    "    A = np.concatenate((A, extractor.transform(images)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(492, 60)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = A[1:]\n",
    "b = np.array(b)\n",
    "A.shape"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
