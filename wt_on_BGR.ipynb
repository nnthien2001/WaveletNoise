{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pywt\n",
    "from scipy.signal import wiener\n",
    "import skimage as skimg \n",
    "\n",
    "from sklearn.preprocessing import (MinMaxScaler, StandardScaler)\n",
    "# from sklearn.model_selection import (train_test_split,)\n",
    "from sklearn.model_selection import (train_test_split, StratifiedKFold,)\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import (SVC)\n",
    "\n",
    "from sklearn.base import (BaseEstimator, TransformerMixin)\n",
    "from sklearn.pipeline import (make_pipeline, make_union,)\n",
    "from sklearn.metrics import (classification_report, accuracy_score)\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLASS():\n",
    "    FAKE = 0\n",
    "    REAL = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_PREFIX = '/home/thienn17/Documents/ICL/'\n",
    "os.path.exists(PATH_PREFIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadImage():\n",
    "    def __init__(self, path_prefix, colorcvt=None):\n",
    "        assert os.path.exists(path_prefix), \"LoadImage, Path does not exist\"\n",
    "        self.path_prefix = path_prefix\n",
    "        self.colorcvt = colorcvt\n",
    "\n",
    "        self.cls_folders = [f for f in os.listdir(path_prefix) if f != 'dummy']\n",
    "        self.cls_id = 0\n",
    "        self.path_walk = os.walk(os.path.join(path_prefix, self.cls_folders[0]))\n",
    "        \n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "    \n",
    "    def reset(self):\n",
    "        self.images = []\n",
    "    \n",
    "    def next_batch(self):\n",
    "        try:\n",
    "            while(True):\n",
    "                abspath, _, files = next(self.path_walk)\n",
    "                if len(files) > 0: break\n",
    "            self.reset()\n",
    "            print(abspath)\n",
    "            for file in tqdm(files):\n",
    "                img = cv2.imread(os.path.join(abspath, file))\n",
    "                if img is not None:\n",
    "                    if self.colorcvt is not None:\n",
    "                        img = cv2.cvtColor(img, self.colorcvt)\n",
    "                    self.images.append(img)\n",
    "                    self.labels.append(CLASS.REAL if self.cls_folders[self.cls_id][0] == 'S' else CLASS.FAKE)\n",
    "            return self.images, self.labels\n",
    "        except StopIteration:\n",
    "            if self.cls_id < len(self.cls_folders)-1:\n",
    "                self.cls_id += 1\n",
    "                self.path_walk = os.walk(os.path.join(self.path_prefix, self.cls_folders[self.cls_id]))\n",
    "                return self.next_batch()\n",
    "\n",
    "        return None\n",
    "\n",
    "    def next_batch_new(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveletTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, wtname = 'haar', level = 3):\n",
    "        '''\n",
    "        waveletname = ['haar', 'db3', 'db5', 'sym2', 'bior5.5', etc.]\n",
    "        level: total number of decomposite level\n",
    "        '''\n",
    "        self.wtname = wtname\n",
    "        self.level = level\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        features = []\n",
    "        for imgBGR in tqdm(X):\n",
    "            img_features = []\n",
    "            for img in np.moveaxis(imgBGR, -1, 0):\n",
    "                wt = pywt.wavedec2(data=img, wavelet=self.wtname, level=self.level)\n",
    "                # appr = wt[0]\n",
    "                details = wt[1:]\n",
    "                wt = []\n",
    "                for levels in details:\n",
    "                    for detail in levels:\n",
    "                        wt.append(detail)\n",
    "                for _wt in wt:\n",
    "                    img_features.append(np.mean(_wt))\n",
    "                    img_features.append(np.var(_wt))\n",
    "            features.append(img_features)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LBPTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, num_points = 8, radius = 1, gray=False, noise=False):\n",
    "        self.num_points = num_points\n",
    "        self.radius = radius\n",
    "        self.gray = gray\n",
    "        self.noise = noise\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        features = []\n",
    "        for img in tqdm(X):\n",
    "            if self.gray:\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "                if self.noise:\n",
    "                    img = img - wiener(img, 5)\n",
    "                features.append(self.get_lbp_features((img,)))\n",
    "            else:\n",
    "                features.append(self.get_lbp_features(np.moveaxis(img, -1, 0)))\n",
    "        return features\n",
    "\n",
    "    def get_lbp_features(self, img_channels):\n",
    "        def local_binary_pattern(img):\n",
    "            lbp = skimg.feature.local_binary_pattern(\n",
    "                img, self.num_points, self.radius, method=\"nri_uniform\").ravel()\n",
    "            # (hist, bins) = np.histogram(lbp.ravel(), bins=59)\n",
    "            bins, hist = np.unique(lbp, return_counts=True)\n",
    "            \n",
    "            hist = hist / len(lbp)\n",
    "            return hist\n",
    "        lbp_features = np.zeros(59)\n",
    "        for img in img_channels:\n",
    "            lbp_features += local_binary_pattern(img)\n",
    "        return lbp_features / len(img_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract & Dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Wavelet\n",
    "# LEVEL = 1\n",
    "# extractor = WaveletTransformer(level=LEVEL)\n",
    "# A = np.empty((1,3*3*2*LEVEL))\n",
    "\n",
    "# LBP\n",
    "extractor = LBPTransformer()\n",
    "A = np.empty((1, 59))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1\n",
      "/home/thienn17/Documents/ICL/SingleCaptureImages/EOS600D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:20<00:00,  4.95it/s]\n",
      "100%|██████████| 100/100 [09:51<00:00,  5.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2\n",
      "/home/thienn17/Documents/ICL/SingleCaptureImages/V550S\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:07<00:00, 13.24it/s]\n",
      "100%|██████████| 100/100 [04:11<00:00,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3\n",
      "/home/thienn17/Documents/ICL/SingleCaptureImages/D40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:10<00:00,  9.59it/s]\n",
      "100%|██████████| 100/100 [04:59<00:00,  3.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 4\n",
      "/home/thienn17/Documents/ICL/SingleCaptureImages/D40/not used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  9.77it/s]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5\n",
      "/home/thienn17/Documents/ICL/SingleCaptureImages/V610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:08<00:00, 12.27it/s]\n",
      "100%|██████████| 100/100 [05:02<00:00,  3.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6\n",
      "/home/thienn17/Documents/ICL/SingleCaptureImages/V550B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:06<00:00, 14.54it/s]\n",
      "100%|██████████| 100/100 [04:08<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7\n",
      "/home/thienn17/Documents/ICL/SingleCaptureImages/RX100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:21<00:00,  4.70it/s]\n",
      "100%|██████████| 100/100 [10:46<00:00,  6.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 8\n",
      "/home/thienn17/Documents/ICL/SingleCaptureImages/TZ7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:18<00:00,  5.38it/s]\n",
      "100%|██████████| 100/100 [08:16<00:00,  4.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 9\n",
      "/home/thienn17/Documents/ICL/SingleCaptureImages/EPM2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:27<00:00,  3.65it/s]\n",
      "100%|██████████| 100/100 [12:08<00:00,  7.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 10\n",
      "/home/thienn17/Documents/ICL/SingleCaptureImages/D70S\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:10<00:00,  9.46it/s]\n",
      "100%|██████████| 100/100 [04:54<00:00,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 11\n",
      "/home/thienn17/Documents/ICL/RecapturedImages/TZ10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 180/180 [00:13<00:00, 13.61it/s]\n",
      "100%|██████████| 180/180 [04:41<00:00,  1.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 12\n",
      "/home/thienn17/Documents/ICL/RecapturedImages/60D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 180/180 [00:10<00:00, 16.60it/s]\n",
      "100%|██████████| 180/180 [03:36<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 13\n",
      "/home/thienn17/Documents/ICL/RecapturedImages/D70s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 180/180 [00:11<00:00, 15.02it/s]\n",
      "100%|██████████| 180/180 [04:07<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 14\n",
      "/home/thienn17/Documents/ICL/RecapturedImages/D3200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 180/180 [00:12<00:00, 14.67it/s]\n",
      "100%|██████████| 180/180 [04:11<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 15\n",
      "/home/thienn17/Documents/ICL/RecapturedImages/600D\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 180/180 [00:11<00:00, 15.23it/s]\n",
      "100%|██████████| 180/180 [04:07<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 16\n",
      "/home/thienn17/Documents/ICL/RecapturedImages/RX100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 180/180 [00:10<00:00, 17.60it/s]\n",
      "100%|██████████| 180/180 [03:37<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 17\n",
      "/home/thienn17/Documents/ICL/RecapturedImages/TZ7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 180/180 [00:11<00:00, 15.25it/s]\n",
      "100%|██████████| 180/180 [04:12<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 18\n",
      "/home/thienn17/Documents/ICL/RecapturedImages/EPM2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 180/180 [00:12<00:00, 14.15it/s]\n",
      "100%|██████████| 180/180 [04:33<00:00,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "b = None\n",
    "loader = LoadImage(PATH_PREFIX, colorcvt=cv2.COLOR_BGR2HSV)\n",
    "batch = 1\n",
    "while(True):\n",
    "    print(\"Batch {}\".format(batch))\n",
    "    batch += 1\n",
    "    \n",
    "    res = loader.next_batch()\n",
    "    if res is None:\n",
    "        break\n",
    "    images, b = res\n",
    "    A = np.concatenate((A, extractor.transform(images)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2345, 59)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = A[1:]\n",
    "b = np.array(b)\n",
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_DUMP = \"./object dump/no union\"\n",
    "os.path.exists(PATH_DUMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE = \"lbp_HSV\"\n",
    "np.save(os.path.join(PATH_DUMP, FILE+\".npy\"), A)\n",
    "np.save(os.path.join(PATH_DUMP, FILE+\"_label.npy\"), b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_DUMP = \"./object dump/no union\"\n",
    "os.path.exists(PATH_DUMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2345, 54)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILE = \"wt_BGR_3lv\"\n",
    "A = np.load(os.path.join(PATH_DUMP, FILE+\".npy\"))\n",
    "b = np.load(os.path.join(PATH_DUMP, FILE+\"_label.npy\"))\n",
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2345, 113)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILE = \"wt_BGR_3lv\"\n",
    "FILE2 = \"lbp_gray\"\n",
    "assert np.all(np.load(os.path.join(PATH_DUMP, FILE+\"_label.npy\")) == np.load(os.path.join(PATH_DUMP, FILE2+\"_label.npy\"))), \"Different order\"\n",
    "\n",
    "A = np.concatenate((np.load(os.path.join(PATH_DUMP, FILE+\".npy\")),\n",
    "                    np.load(os.path.join(PATH_DUMP, FILE2+\".npy\"))),\n",
    "                   axis=1)\n",
    "b = np.load(os.path.join(PATH_DUMP, FILE+\"_label.npy\"))\n",
    "A.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_train, A_test, b_train, b_test = train_test_split(A, b,\n",
    "                                                    train_size=0.8,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(StandardScaler(), SVC())\n",
    "pipe = pipe.fit(A_train, b_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98       288\n",
      "           1       0.98      0.94      0.96       181\n",
      "\n",
      "    accuracy                           0.97       469\n",
      "   macro avg       0.97      0.96      0.97       469\n",
      "weighted avg       0.97      0.97      0.97       469\n",
      "\n"
     ]
    }
   ],
   "source": [
    "b_pred = pipe.predict(A_test)\n",
    "print(classification_report(b_test, b_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold(_estimator):\n",
    "    # print(_estimator)\n",
    "    \n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=12)\n",
    "    score = 0\n",
    "    for k, (i_train, i_test) in enumerate(kf.split(A, b)):\n",
    "        model = _estimator.fit(A[i_train,], b[i_train])\n",
    "\n",
    "        y_pred = model.predict(A[i_test,])\n",
    "        acc = accuracy_score(y_true=b[i_test], y_pred=y_pred)\n",
    "        score += acc\n",
    "\n",
    "        print(\"[Fold {}] Acc: {:.3f}\".format(k+1, acc))\n",
    "        # print(classification_report(y_true=b[i_test], y_pred=y_pred))\n",
    "\n",
    "    print(\"Mean acc: {:.3f}\\n\".format(score/kf.get_n_splits()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1] Acc: 0.957\n",
      "[Fold 2] Acc: 0.949\n",
      "[Fold 3] Acc: 0.936\n",
      "[Fold 4] Acc: 0.955\n",
      "[Fold 5] Acc: 0.938\n",
      "Mean acc: 0.947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kfold(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
